{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:3em;color:black;\"> Session 4 - Lab Exercise 6</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Students in this Group:\n",
    "\n",
    "- Gabriel Okazaki\n",
    "- Julio Socher\n",
    "- Kateryna Solonenko\n",
    "- Mohit Sabharwal\n",
    "- Riya Gupta\n",
    "- Vaibhav Saini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can download the original Kyphosis dataset from kaggle at https://www.kaggle.com/abbasit/kyphosis-dataset?select=kyphosis.csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kyphosis_df = pd.read_csv('kyphosis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Kyphosis_df.drop('Kyphosis',axis=1)\n",
    "y = Kyphosis_df['Kyphosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Criterion: gini, Splitter: best, Min Samples Split: 2\n",
      "Confusion Matrix: \n",
      " [[19  2]\n",
      " [ 2  2]]\n",
      "Accuracy: 0.84\n",
      "Precision: 0.5\n",
      "Recall: 0.5 \n",
      "\n",
      "Accuracy with Criterion: gini, Splitter: best, Min Samples Split: 5\n",
      "Confusion Matrix: \n",
      " [[16  5]\n",
      " [ 2  2]]\n",
      "Accuracy: 0.72\n",
      "Precision: 0.2857142857142857\n",
      "Recall: 0.5 \n",
      "\n",
      "Accuracy with Criterion: gini, Splitter: random, Min Samples Split: 2\n",
      "Confusion Matrix: \n",
      " [[19  2]\n",
      " [ 3  1]]\n",
      "Accuracy: 0.8\n",
      "Precision: 0.3333333333333333\n",
      "Recall: 0.25 \n",
      "\n",
      "Accuracy with Criterion: gini, Splitter: random, Min Samples Split: 5\n",
      "Confusion Matrix: \n",
      " [[20  1]\n",
      " [ 3  1]]\n",
      "Accuracy: 0.84\n",
      "Precision: 0.5\n",
      "Recall: 0.25 \n",
      "\n",
      "Accuracy with Criterion: entropy, Splitter: best, Min Samples Split: 2\n",
      "Confusion Matrix: \n",
      " [[19  2]\n",
      " [ 2  2]]\n",
      "Accuracy: 0.84\n",
      "Precision: 0.5\n",
      "Recall: 0.5 \n",
      "\n",
      "Accuracy with Criterion: entropy, Splitter: best, Min Samples Split: 5\n",
      "Confusion Matrix: \n",
      " [[16  5]\n",
      " [ 2  2]]\n",
      "Accuracy: 0.72\n",
      "Precision: 0.2857142857142857\n",
      "Recall: 0.5 \n",
      "\n",
      "Accuracy with Criterion: entropy, Splitter: random, Min Samples Split: 2\n",
      "Confusion Matrix: \n",
      " [[18  3]\n",
      " [ 3  1]]\n",
      "Accuracy: 0.76\n",
      "Precision: 0.25\n",
      "Recall: 0.25 \n",
      "\n",
      "Accuracy with Criterion: entropy, Splitter: random, Min Samples Split: 5\n",
      "Confusion Matrix: \n",
      " [[19  2]\n",
      " [ 1  3]]\n",
      "Accuracy: 0.88\n",
      "Precision: 0.6\n",
      "Recall: 0.75 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selecting the right \"parameters/hyperparameters of ML models can significantly affect their performance\".\n",
    "# let's begin exploring those parameters more for a DT model.\n",
    "'''\n",
    "DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    splitter='best',\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features=None,\n",
    "    random_state=None,\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    class_weight=None,\n",
    "    presort=False,\n",
    ")\n",
    "'''\n",
    "# Let's consider these three parameters: criterion, splitter, min_samples_split\n",
    "    # for parameters consider two cases 'gini' and 'entropy'\n",
    "    # for splitter consider two cases 'best' and 'random'\n",
    "    # for min_samples_split consider two cases 2 and 5\n",
    "# explain and discuss your findings\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def test_decision_tree_parameters(X_train, y_train, X_test, y_test):\n",
    "    criterions = ['gini', 'entropy']\n",
    "    splitters = ['best', 'random']\n",
    "    min_samples_splits = [2, 5]\n",
    "\n",
    "    for criterion in criterions:\n",
    "        for splitter in splitters:\n",
    "            for min_samples_split in min_samples_splits:\n",
    "                clf = DecisionTreeClassifier(criterion=criterion, splitter=splitter, min_samples_split=min_samples_split)\n",
    "                clf.fit(X_train, y_train)\n",
    "                predictions = clf.predict(X_test)\n",
    "                cm = confusion_matrix(y_test, predictions)\n",
    "                accuracy = accuracy_score(y_test, predictions)\n",
    "                precision = precision_score(y_test, predictions, pos_label='present')\n",
    "                recall = recall_score(y_test, predictions, pos_label='present')\n",
    "                print(f\"Accuracy with Criterion: {criterion}, Splitter: {splitter}, Min Samples Split: {min_samples_split}\")\n",
    "                print(f\"Confusion Matrix: \\n {cm}\")\n",
    "                print(f\"Accuracy: {accuracy}\")\n",
    "                print(f\"Precision: {precision}\")\n",
    "                print(f\"Recall: {recall} \\n\")\n",
    "test_decision_tree_parameters(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "The conclusion about those results is that the best model is the entropy with a larger split size, but this does not mean anything since\n",
    "first, we need to understand the problem we are trying to solve. In some scenarios, we can't have a False Positive, and in some cases, we \n",
    "can't have a False Negative, so that determination is essential for our decision on which model to use.\n",
    "\n",
    "Analyzing the raw results of the mixed parameters we have we can see that the entropy with a larger split size is the most accurate and\n",
    "precise model while using the same model but with a smaller split size gave us the worst precision. The worst accuracies are found in \n",
    "both models and for both with the best splitter and a higher number of samples per split. We can infer that the best splitter works with\n",
    "a smaller split size.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
